# PIPELINE DEFINITION
# Name: model-training-pipeline
# Description: A pipeline to train models on the movielens dataset for recommenders
# Inputs:
#    hot_reload_model_id: str [Default: 'none']
#    minio_bucket: str [Default: 'datasets']
#    mlflow_experiment_name: str [Default: 'recommender']
#    mlflow_registered_model_name: str [Default: 'recommender_production']
#    mlflow_uri: str [Default: 'http://192.168.1.90:8080']
#    model_dropout_rate: float [Default: 0.2]
#    model_embedding_factors: int [Default: 20.0]
#    model_hidden_dims: int [Default: 256.0]
#    model_promote_precision_threshold: float [Default: -0.3]
#    model_promote_recall_threshold: float [Default: -0.2]
#    model_promote_rms_threshold: float [Default: 0.0001]
#    number_of_negative_samples: int [Default: 10.0]
#    optimizer_gamma: float [Default: 0.1]
#    optimizer_step_size: float [Default: 10.0]
#    shuffle_testing_data: bool [Default: True]
#    shuffle_training_data: bool [Default: True]
#    testing_batch_size: int [Default: 64.0]
#    training_batch_size: int [Default: 64.0]
#    training_dataset_name: str [Default: 'ml-25m']
#    training_epochs: int [Default: 30.0]
#    training_learning_rate: float [Default: 0.001]
#    validation_batch_size: int [Default: 32.0]
#    validation_threshold: int [Default: 3.0]
#    validation_top_k: int [Default: 50.0]
components:
  comp-get-dataset:
    executorLabel: exec-get-dataset
    inputDefinitions:
      parameters:
        bucket:
          parameterType: STRING
        dataset_name:
          parameterType: STRING
        split:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-get-dataset-2:
    executorLabel: exec-get-dataset-2
    inputDefinitions:
      parameters:
        bucket:
          parameterType: STRING
        dataset_name:
          parameterType: STRING
        split:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-get-dataset-metadata:
    executorLabel: exec-get-dataset-metadata
    inputDefinitions:
      parameters:
        bucket:
          parameterType: STRING
        dataset_name:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRUCT
  comp-negative-sampling:
    executorLabel: exec-negative-sampling
    inputDefinitions:
      parameters:
        bucket:
          parameterType: STRING
        dataset_name:
          parameterType: STRING
        num_ng_test:
          parameterType: NUMBER_INTEGER
        split:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        negative_sampled_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-promote-model-to-staging:
    executorLabel: exec-promote-model-to-staging
    inputDefinitions:
      parameters:
        mlflow_uri:
          parameterType: STRING
        model_run_id:
          parameterType: STRING
        precision_threshold:
          parameterType: NUMBER_DOUBLE
        recall_threshold:
          parameterType: NUMBER_DOUBLE
        registered_model_name:
          parameterType: STRING
        rms_threshold:
          parameterType: NUMBER_DOUBLE
        top_k:
          parameterType: NUMBER_INTEGER
  comp-qa-data:
    executorLabel: exec-qa-data
    inputDefinitions:
      parameters:
        bucket:
          defaultValue: datasets
          isOptional: true
          parameterType: STRING
        dataset:
          defaultValue: ml-25m
          isOptional: true
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        testing_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        training_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        hot_reload_model_run_id:
          parameterType: STRING
        mlflow_experiment_name:
          parameterType: STRING
        mlflow_run_id:
          parameterType: STRING
        mlflow_tags:
          parameterType: STRUCT
        mlflow_uri:
          parameterType: STRING
        model_dropout_rate:
          parameterType: NUMBER_DOUBLE
        model_embedding_factors:
          parameterType: NUMBER_INTEGER
        model_hidden_dims:
          parameterType: NUMBER_INTEGER
        model_learning_rate:
          parameterType: NUMBER_DOUBLE
        optimizer_gamma:
          parameterType: NUMBER_DOUBLE
        optimizer_step_size:
          parameterType: NUMBER_DOUBLE
        shuffle_testing_data:
          parameterType: BOOLEAN
        shuffle_training_data:
          parameterType: BOOLEAN
        test_batch_size:
          parameterType: NUMBER_INTEGER
        train_batch_size:
          parameterType: NUMBER_INTEGER
        training_data_metadata:
          parameterType: STRUCT
        training_epochs:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
  comp-validate-model:
    executorLabel: exec-validate-model
    inputDefinitions:
      artifacts:
        validation_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        mlflow_uri:
          parameterType: STRING
        model_run_id:
          parameterType: STRING
        threshold:
          parameterType: NUMBER_INTEGER
        top_k:
          parameterType: NUMBER_INTEGER
        val_batch_size:
          parameterType: NUMBER_INTEGER
deploymentSpec:
  executors:
    exec-get-dataset:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - get_dataset
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'fastparquet'\
          \ 'numpy' 'pyarrow' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef get_dataset(bucket: str, dataset_name: str, split: str, output_dataset:\
          \ Output[Dataset]):\n    from pyarrow import fs, parquet\n    import pandas\
          \ as pd\n\n    assert split in ['test', 'train', 'val']\n    minio = fs.S3FileSystem(\n\
          \        endpoint_override='http://minio-service.kubeflow:9000',\n     \
          \    access_key='minio',\n         secret_key='minio123',\n         scheme='http')\n\
          \    paraquet_data = minio.open_input_file(f'{bucket}/{dataset_name}/{split}.parquet.gzip')\n\
          \    df = parquet.read_table(paraquet_data).to_pandas()\n    pd.to_pickle(df,\
          \ output_dataset.path)\n\n"
        image: python:3.9
    exec-get-dataset-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - get_dataset
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'fastparquet'\
          \ 'numpy' 'pyarrow' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef get_dataset(bucket: str, dataset_name: str, split: str, output_dataset:\
          \ Output[Dataset]):\n    from pyarrow import fs, parquet\n    import pandas\
          \ as pd\n\n    assert split in ['test', 'train', 'val']\n    minio = fs.S3FileSystem(\n\
          \        endpoint_override='http://minio-service.kubeflow:9000',\n     \
          \    access_key='minio',\n         secret_key='minio123',\n         scheme='http')\n\
          \    paraquet_data = minio.open_input_file(f'{bucket}/{dataset_name}/{split}.parquet.gzip')\n\
          \    df = parquet.read_table(paraquet_data).to_pandas()\n    pd.to_pickle(df,\
          \ output_dataset.path)\n\n"
        image: python:3.9
    exec-get-dataset-metadata:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - get_dataset_metadata
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ 'pandas' 'fastparquet' 'pyarrow' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef get_dataset_metadata(bucket:str , dataset_name:str) -> Dict[str,\
          \ int]:\n    from pyarrow import fs, parquet\n    valid_splits = ['test',\
          \ 'train', 'val']\n    data_map = {'n_users': 0, 'n_items': 0}\n    minio\
          \ = fs.S3FileSystem(\n        endpoint_override='http://minio-service.kubeflow:9000',\n\
          \         access_key='minio',\n         secret_key='minio123',\n       \
          \  scheme='http')\n\n    for valid_split in valid_splits:\n        paraquet_data\
          \ = minio.open_input_file(f'{bucket}/{dataset_name}/{valid_split}.parquet.gzip')\n\
          \        df = parquet.read_table(paraquet_data).to_pandas()\n        print(df.head())\n\
          \        data_map['n_users'] = max(data_map['n_users'], int(df.userId.max()))\n\
          \        data_map['n_items'] = max(data_map['n_items'], int(df.movieId.max()))\n\
          \n    #assert list(data_map.keys()) == split, f\"Mismatched or invalid splits.\
          \ Received {split} but can only process {valid_splits}\"\n    return data_map\n\
          \n"
        image: python:3.9
    exec-negative-sampling:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - negative_sampling
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'fastparquet'\
          \ 'numpy' 'pyarrow' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef negative_sampling(num_ng_test:int, bucket:str , dataset_name:str,\
          \ split: str, negative_sampled_dataset: Output[Dataset]):\n    import pandas\
          \ as pd\n    from pyarrow import fs, parquet\n    import numpy as np\n\n\
          \    minio = fs.S3FileSystem(\n        endpoint_override='http://minio-service.kubeflow:9000',\n\
          \         access_key='minio',\n         secret_key='minio123',\n       \
          \  scheme='http')\n    paraquet_data = minio.open_input_file(f'{bucket}/{dataset_name}/{split}.parquet.gzip')\n\
          \    ratings = parquet.read_table(paraquet_data).to_pandas()\n    item_pool\
          \ = set(ratings['movieId'].unique())\n    interact_status = (\n\t\t\tratings.groupby('userId')['movieId']\n\
          \t\t\t.apply(set)\n\t\t\t.reset_index()\n\t\t\t.rename(columns={'movieId':\
          \ 'interacted_items'}))\n    interact_status['negative_samples'] = interact_status['interacted_items'].apply(lambda\
          \ x: np.random.choice(list(item_pool - x), num_ng_test))\n    interact_status['rating']\
          \ = 0.0\n    interact_status['timestamp'] = 1051631039\n    interact_status\
          \ = interact_status.drop(columns=['interacted_items']).explode('negative_samples').rename(columns={'negative_samples':'movieId'})\n\
          \    #ret = ratings.append(interact_status, ignore_index=True)\n    ret\
          \ = pd.concat([ratings, interact_status], ignore_index=True)\n    pd.to_pickle(ret,\
          \ negative_sampled_dataset.path)\n\n"
        image: python:3.9
    exec-promote-model-to-staging:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - promote_model_to_staging
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'mlflow' &&\
          \ \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef promote_model_to_staging(\n    model_run_id: str, \n    registered_model_name:\
          \ str,\n    rms_threshold: float, \n    precision_threshold: float,\n  \
          \  top_k: int,\n    recall_threshold: float,\n    mlflow_uri: str):\n\n\
          \    import mlflow.pytorch\n    import mlflow\n    from mlflow import MlflowClient\n\
          \    from mlflow.exceptions import RestException\n\n    mlflow.set_tracking_uri(uri=mlflow_uri)\n\
          \    client = MlflowClient()\n\n    current_staging = None\n    try:\n \
          \       current_staging = client.get_model_version_by_alias(registered_model_name,\
          \ \"staging\")\n    except RestException:\n        print(\"No staging model\
          \ found. Auto upgrade current run to staging.\")\n\n    if current_staging.run_id\
          \ == model_run_id:\n        print(\"Input run is already the current staging.\"\
          )\n        return\n\n    if current_staging is not None:\n        current_staging_model_data\
          \ = client.get_run(current_staging.run_id).data.to_dictionary()\n      \
          \  staging_model_metrics = current_staging_model_data['metrics']\n\n   \
          \     new_model_data = client.get_run(model_run_id).data.to_dictionary()\n\
          \        new_model_metrics = new_model_data['metrics']\n\n        if (new_model_metrics['rms']\
          \ - staging_model_metrics['rms']) > rms_threshold:\n            return\n\
          \n        if (new_model_metrics[f'precision_{top_k}'] - staging_model_metrics[f'precision_{top_k}'])\
          \ < precision_threshold:\n            return\n\n        if (new_model_metrics[f'recall_{top_k}']\
          \ - staging_model_metrics[f'recall_{top_k}']) < recall_threshold:\n    \
          \        return\n\n    result = mlflow.register_model(f\"runs:/{model_run_id}/model\"\
          , \"recommender_production\")\n    client.set_registered_model_alias(\"\
          recommender_production\", \"staging\", result.version)\n\n"
        image: python:3.9
    exec-qa-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - qa_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.10.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pyarrow' 'pandas'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef qa_data(bucket:str = 'datasets', dataset:str = 'ml-25m'):\n \
          \   from pyarrow import fs, parquet\n    print(\"Running QA\")\n    minio\
          \ = fs.S3FileSystem(\n        endpoint_override='http://minio-service.kubeflow:9000',\n\
          \         access_key='minio',\n         secret_key='minio123',\n       \
          \  scheme='http')\n    train_parquet = minio.open_input_file(f'{bucket}/{dataset}/train.parquet.gzip')\n\
          \    df = parquet.read_table(train_parquet).to_pandas()\n    assert df.shape[1]\
          \ == 4\n    assert df.shape[0] >= 0.75 * 25 * 1e6\n    print('QA passed!')\n\
          \n"
        image: python:3.9
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu\
          \ --trusted-host https://download.pytorch.org/whl/cpu 'kfp==2.10.1' '--no-deps'\
          \ 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m\
          \ pip install --quiet --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu\
          \ --trusted-host https://download.pytorch.org/whl/cpu 'torch' 'torchvision'\
          \ 'torchaudio' 'mlflow' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(mlflow_experiment_name: str, mlflow_run_id: str,\
          \ mlflow_tags: dict, mlflow_uri: str,\n                hot_reload_model_run_id:\
          \ str, training_data: Input[Dataset], training_data_metadata: Dict[str,\
          \ int],\n                testing_data: Input[Dataset],\n               \
          \ model_embedding_factors: int, model_learning_rate: float, model_hidden_dims:\
          \ int, model_dropout_rate: float,\n                optimizer_step_size:\
          \ float, optimizer_gamma: float,\n                training_epochs: int,\n\
          \                train_batch_size: int, test_batch_size: int, shuffle_training_data:\
          \ bool, shuffle_testing_data: bool) -> str:\n    input_params = {}\n   \
          \ for k, v in locals().items():\n        if k == 'input_params':\n     \
          \       continue\n        input_params[k] = v\n    import torch\n    from\
          \ torch.autograd import Variable\n    from torch.utils.data import DataLoader\n\
          \    import mlflow\n    from torchinfo import summary\n    from mlflow.models\
          \ import infer_signature\n    from torch.utils.data import Dataset\n   \
          \ import pandas as pd\n\n    class datasetReader(Dataset):\n        def\
          \ __init__(self, df, dataset_name):\n            self.df = df\n        \
          \    self.name = dataset_name\n            print(f\"{self.name} : {self.df.shape[0]}\"\
          )\n\n        def __len__(self):\n            return self.df.shape[0]\n\n\
          \        def __getitem__(self, idx):\n            sd = self.df.iloc[idx]\n\
          \            user = sd['userId']\n            item = sd['movieId']\n   \
          \         rating = sd['rating']\n            return torch.tensor(user-1).long(),\
          \ torch.tensor(item-1).long(), torch.tensor(rating).float()\n\n    class\
          \ MatrixFactorization(torch.nn.Module):\n        def __init__(self, n_users,\
          \ n_items, n_factors, hidden_dim, dropout_rate):\n            super().__init__()\n\
          \            self.n_items = n_items\n            self.user_factors = torch.nn.Embedding(n_users+1,\
          \ \n                                               n_factors,\n        \
          \                                       sparse=False)\n            self.item_factors\
          \ = torch.nn.Embedding(n_items+1, \n                                   \
          \            n_factors,\n                                              \
          \ sparse=False)\n\n            self.linear = torch.nn.Linear(in_features=n_factors,\
          \ out_features=hidden_dim)\n            self.linear2 = torch.nn.Linear(in_features=hidden_dim,\
          \ out_features=1)\n            self.dropout = torch.nn.Dropout(p=dropout_rate)\n\
          \            self.relu = torch.nn.ReLU()\n\n        def forward(self, user,\
          \ item):\n            user_embedding = self.user_factors(user)\n       \
          \     item_embedding = self.item_factors(item)\n            embeddding_vector\
          \ = torch.mul(user_embedding, item_embedding)\n            x = self.relu(self.linear(embeddding_vector))\n\
          \            x = self.dropout(x)\n            rating = self.linear2(x)\n\
          \            return rating\n\n    train_dataset = datasetReader(pd.read_pickle(training_data.path),\
          \ dataset_name='train')\n    test_dataset = datasetReader(pd.read_pickle(testing_data.path),\
          \ dataset_name='test')\n\n    n_users = training_data_metadata['n_users']\n\
          \    n_items = training_data_metadata['n_items']\n\n    if hot_reload_model_run_id\
          \ == 'none':\n        hot_reload_model_run_id = None\n\n    if hot_reload_model_run_id:\n\
          \        model_uri = f\"runs:/{hot_reload_model_run_id}/model\"\n      \
          \  model = mlflow.pytorch.load_model(model_uri)\n    else:\n        model\
          \ = MatrixFactorization(n_users, n_items, n_factors=model_embedding_factors,\
          \ hidden_dim=model_hidden_dims, dropout_rate=model_dropout_rate)\n\n   \
          \ optimizer = torch.optim.SGD(model.parameters(), lr=model_learning_rate)\n\
          \    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=optimizer_step_size,\
          \ gamma=optimizer_gamma)\n    loss_func = torch.nn.L1Loss()\n    train_dataloader\
          \ = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=shuffle_training_data)\n\
          \    test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size,\
          \ shuffle=shuffle_testing_data)\n\n    # Set our tracking server uri for\
          \ logging\n    mlflow.set_tracking_uri(uri=mlflow_uri)\n\n    # Create a\
          \ new MLflow Experiment\n    mlflow.set_experiment(mlflow_experiment_name)\n\
          \n    if mlflow_run_id == \"\":\n        mlflow_run_id = None\n\n    with\
          \ mlflow.start_run(run_id=mlflow_run_id) as run:\n        current_run_id\
          \ = run.info.run_id\n        for k,v in input_params.items():\n        \
          \    if 'mlflow_' not in k:\n                mlflow.log_param(k, v)\n  \
          \      mlflow.log_param(\"loss_function\", loss_func.__class__.__name__)\n\
          \        #mlflow.log_param(\"metric_function\", metric_fn.__class__.__name__,\n\
          \        mlflow.log_param(\"optimizer\", \"SGD\")\n        mlflow.log_params({'n_user':\
          \ n_users, 'n_items': n_items})\n\n        for k,v in mlflow_tags.items():\n\
          \            mlflow.set_tag(k, v)\n\n        with open(\"model_summary.txt\"\
          , \"w\") as f:\n            f.write(str(summary(model)))\n        mlflow.log_artifact(\"\
          model_summary.txt\")\n\n        model_signature = None\n\n        for train_iter\
          \ in range(training_epochs):\n            print(train_iter)\n          \
          \  model.train()\n            t_loss = 0\n            t_count = 0\n    \
          \        for row, col, rating in train_dataloader:\n                # Predict\
          \ and calculate loss\n                #try:\n                prediction\
          \ = model(row, col)\n                if model_signature is None:\n     \
          \               model_signature = infer_signature({'user': row.cpu().detach().numpy(),\
          \ 'movie': col.cpu().detach().numpy()}, prediction.cpu().detach().numpy())\n\
          \n                #except Exception as e:\n                #print(f\"R:{row},\
          \ C:{col}\")\n                loss = loss_func(prediction, rating.unsqueeze(1))\n\
          \                t_loss += loss\n                t_count += 1\n\n      \
          \          # Backpropagate\n                loss.backward()\n\n        \
          \        # Update the parameters\n                optimizer.step()\n   \
          \             optimizer.zero_grad()\n            mlflow.log_metric(\"avg_training_loss\"\
          , f\"{(t_loss/t_count):3f}\", step=train_iter)\n            scheduler.step()\n\
          \            model.eval()\n            te_loss = 0\n            te_count\
          \ = 0\n            print('Evaluating')\n            with torch.no_grad():\n\
          \                #HR, NDCG = metrics(model, test_dataloader, 5)\n      \
          \          for row, col,rating in test_dataloader:\n                   \
          \ prediction = model(row, col)\n                    loss = loss_func(prediction,\
          \ rating.unsqueeze(1))\n                    te_loss += loss\n          \
          \          te_count += 1\n            mlflow.log_metric(\"avg_testing_loss\"\
          , f\"{(te_loss/te_count):3f}\", step=train_iter)\n            #print(f\"\
          HR: {HR} NDCG:{NDCG}\")\n            print(f\"Test loss: {te_loss/te_count}\"\
          )\n            print(f\"Train loss: {t_loss/t_count}\")\n\n        mlflow.pytorch.log_model(model,\
          \ \"model\", signature=model_signature)\n    return current_run_id\n\n"
        image: python:3.9
    exec-validate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu\
          \ --trusted-host https://download.pytorch.org/whl/cpu 'kfp==2.10.1' '--no-deps'\
          \ 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m\
          \ pip install --quiet --no-warn-script-location --index-url https://download.pytorch.org/whl/cpu\
          \ --trusted-host https://download.pytorch.org/whl/cpu 'scikit-metrics' 'torch'\
          \ 'torchvision' 'torchaudio' 'mlflow' 'pandas' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_model(\n    model_run_id: str, \n    top_k: int,\n \
          \   threshold: int,\n    val_batch_size: int,\n    mlflow_uri: str, \n \
          \   validation_dataset: Input[Dataset]):\n\n    # https://pureai.substack.com/p/recommender-systems-with-pytorch\n\
          \    from collections import defaultdict\n    import torch\n    import mlflow.pytorch\n\
          \    import mlflow\n    from sklearn.metrics import root_mean_squared_error\n\
          \    from torch.utils.data import DataLoader\n    import pandas as pd\n\n\
          \    mlflow.set_tracking_uri(uri=mlflow_uri)\n\n    model_uri = f\"runs:/{model_run_id}/model\"\
          \n    recommendation_model = mlflow.pytorch.load_model(model_uri)\n    class\
          \ datasetReader(Dataset):\n        def __init__(self, df, dataset_name):\n\
          \            self.df = df\n            self.name = dataset_name\n      \
          \      print(f\"{self.name} : {self.df.shape[0]}\")\n\n        def __len__(self):\n\
          \            return self.df.shape[0]\n\n        def __getitem__(self, idx):\n\
          \            sd = self.df.iloc[idx]\n            user = sd['user_id']\n\
          \            item = sd['item_id']\n            rating = sd['rating']\n \
          \           return torch.tensor(user-1).long(), torch.tensor(item-1).long(),\
          \ torch.tensor(rating).float()\n\n    def calculate_precision_recall(user_ratings,\
          \ k, threshold):\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n\
          \        n_rel = sum(true_r >= threshold for _, true_r in user_ratings)\n\
          \        n_rec_k = sum(est >= threshold for est, _ in user_ratings[:k])\n\
          \        n_rel_and_rec_k = sum((true_r >= threshold) and (est >= threshold)\
          \ for est, true_r in user_ratings[:k])\n\n        precision = n_rel_and_rec_k\
          \ / n_rec_k if n_rec_k != 0 else 1\n        recall = n_rel_and_rec_k / n_rel\
          \ if n_rel != 0 else 1\n        return precision, recall\n\n    user_ratings_comparison\
          \ = defaultdict(list)\n\n    val_data = datasetReader(pd.read_pickle(validation_dataset.path),\
          \ dataset_name='val')\n    val_dataloader = DataLoader(val_data, batch_size=val_batch_size,\
          \ shuffle=True)\n\n    y_pred = []\n    y_true = []\n\n    recommendation_model.eval()\n\
          \n    with torch.no_grad():\n        for users, movies, ratings in val_dataloader:\n\
          \            output = recommendation_model(users, movies)\n\n          \
          \  y_pred.append(output.sum().item() / len(users))\n            y_true.append(ratings.sum().item()\
          \ / len(users))\n\n            for user, pred, true in zip(users, output,\
          \ ratings):\n                user_ratings_comparison[user.item()].append((pred[0].item(),\
          \ true.item()))\n\n    user_precisions = dict()\n    user_based_recalls\
          \ = dict()\n\n    k = top_k\n\n    for user_id, user_ratings in user_ratings_comparison.items():\n\
          \        precision, recall = calculate_precision_recall(user_ratings, k,\
          \ threshold)\n        user_precisions[user_id] = precision\n        user_based_recalls[user_id]\
          \ = recall\n\n\n    average_precision = sum(prec for prec in user_precisions.values())\
          \ / len(user_precisions)\n    average_recall = sum(rec for rec in user_based_recalls.values())\
          \ / len(user_based_recalls)\n    rms = root_mean_squared_error(y_true, y_pred,\
          \ squared=False)\n\n    print(f\"precision_{k}: {average_precision:.4f}\"\
          )\n    print(f\"recall_{k}: {average_recall:.4f}\")\n    print(f\"rms: {rms:.4f}\"\
          )\n    mlflow.log_metric(f\"precision_{k}\", average_precision, run_id=model_run_id)\n\
          \    mlflow.log_metric(f\"recall_{k}\", average_recall, run_id=model_run_id)\n\
          \    mlflow.log_metric(\"rms\", rms, run_id=model_run_id)\n\n"
        image: python:3.9
pipelineInfo:
  description: A pipeline to train models on the movielens dataset for recommenders
  name: model-training-pipeline
root:
  dag:
    tasks:
      get-dataset:
        cachingOptions: {}
        componentRef:
          name: comp-get-dataset
        inputs:
          parameters:
            bucket:
              componentInputParameter: minio_bucket
            dataset_name:
              componentInputParameter: training_dataset_name
            split:
              runtimeValue:
                constant: test
        taskInfo:
          name: get-test-data
      get-dataset-2:
        cachingOptions: {}
        componentRef:
          name: comp-get-dataset-2
        inputs:
          parameters:
            bucket:
              componentInputParameter: minio_bucket
            dataset_name:
              componentInputParameter: training_dataset_name
            split:
              runtimeValue:
                constant: val
        taskInfo:
          name: get-validation-data
      get-dataset-metadata:
        cachingOptions: {}
        componentRef:
          name: comp-get-dataset-metadata
        dependentTasks:
        - qa-data
        inputs:
          parameters:
            bucket:
              componentInputParameter: minio_bucket
            dataset_name:
              componentInputParameter: training_dataset_name
        taskInfo:
          name: get-dataset-metadata
      negative-sampling:
        cachingOptions: {}
        componentRef:
          name: comp-negative-sampling
        dependentTasks:
        - get-dataset-metadata
        inputs:
          parameters:
            bucket:
              componentInputParameter: minio_bucket
            dataset_name:
              componentInputParameter: training_dataset_name
            num_ng_test:
              componentInputParameter: number_of_negative_samples
            split:
              runtimeValue:
                constant: train
        taskInfo:
          name: negative-sampling
      promote-model-to-staging:
        cachingOptions: {}
        componentRef:
          name: comp-promote-model-to-staging
        dependentTasks:
        - train-model
        - validate-model
        inputs:
          parameters:
            mlflow_uri:
              componentInputParameter: mlflow_uri
            model_run_id:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model
            precision_threshold:
              componentInputParameter: model_promote_precision_threshold
            recall_threshold:
              componentInputParameter: model_promote_recall_threshold
            registered_model_name:
              componentInputParameter: mlflow_registered_model_name
            rms_threshold:
              componentInputParameter: model_promote_rms_threshold
            top_k:
              componentInputParameter: validation_top_k
        taskInfo:
          name: promote-model-to-staging
      qa-data:
        cachingOptions: {}
        componentRef:
          name: comp-qa-data
        inputs:
          parameters:
            bucket:
              componentInputParameter: minio_bucket
        taskInfo:
          name: qa-training-data
      train-model:
        cachingOptions: {}
        componentRef:
          name: comp-train-model
        dependentTasks:
        - get-dataset
        - get-dataset-metadata
        - negative-sampling
        inputs:
          artifacts:
            testing_data:
              taskOutputArtifact:
                outputArtifactKey: output_dataset
                producerTask: get-dataset
            training_data:
              taskOutputArtifact:
                outputArtifactKey: negative_sampled_dataset
                producerTask: negative-sampling
          parameters:
            hot_reload_model_run_id:
              componentInputParameter: hot_reload_model_id
            mlflow_experiment_name:
              componentInputParameter: mlflow_experiment_name
            mlflow_run_id:
              runtimeValue:
                constant: ''
            mlflow_tags:
              runtimeValue:
                constant: {}
            mlflow_uri:
              componentInputParameter: mlflow_uri
            model_dropout_rate:
              componentInputParameter: model_dropout_rate
            model_embedding_factors:
              componentInputParameter: model_embedding_factors
            model_hidden_dims:
              componentInputParameter: model_hidden_dims
            model_learning_rate:
              componentInputParameter: training_learning_rate
            optimizer_gamma:
              componentInputParameter: optimizer_gamma
            optimizer_step_size:
              componentInputParameter: optimizer_step_size
            shuffle_testing_data:
              componentInputParameter: shuffle_testing_data
            shuffle_training_data:
              componentInputParameter: shuffle_training_data
            test_batch_size:
              componentInputParameter: testing_batch_size
            train_batch_size:
              componentInputParameter: training_batch_size
            training_data_metadata:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: get-dataset-metadata
            training_epochs:
              componentInputParameter: training_epochs
        taskInfo:
          name: train-model
      validate-model:
        cachingOptions: {}
        componentRef:
          name: comp-validate-model
        dependentTasks:
        - get-dataset-2
        - train-model
        inputs:
          artifacts:
            validation_dataset:
              taskOutputArtifact:
                outputArtifactKey: output_dataset
                producerTask: get-dataset-2
          parameters:
            mlflow_uri:
              componentInputParameter: mlflow_uri
            model_run_id:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: train-model
            threshold:
              componentInputParameter: validation_threshold
            top_k:
              componentInputParameter: validation_top_k
            val_batch_size:
              componentInputParameter: validation_batch_size
        taskInfo:
          name: validate-model
  inputDefinitions:
    parameters:
      hot_reload_model_id:
        defaultValue: none
        isOptional: true
        parameterType: STRING
      minio_bucket:
        defaultValue: datasets
        isOptional: true
        parameterType: STRING
      mlflow_experiment_name:
        defaultValue: recommender
        isOptional: true
        parameterType: STRING
      mlflow_registered_model_name:
        defaultValue: recommender_production
        isOptional: true
        parameterType: STRING
      mlflow_uri:
        defaultValue: http://192.168.1.90:8080
        isOptional: true
        parameterType: STRING
      model_dropout_rate:
        defaultValue: 0.2
        isOptional: true
        parameterType: NUMBER_DOUBLE
      model_embedding_factors:
        defaultValue: 20.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      model_hidden_dims:
        defaultValue: 256.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      model_promote_precision_threshold:
        defaultValue: -0.3
        isOptional: true
        parameterType: NUMBER_DOUBLE
      model_promote_recall_threshold:
        defaultValue: -0.2
        isOptional: true
        parameterType: NUMBER_DOUBLE
      model_promote_rms_threshold:
        defaultValue: 0.0001
        isOptional: true
        parameterType: NUMBER_DOUBLE
      number_of_negative_samples:
        defaultValue: 10.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      optimizer_gamma:
        defaultValue: 0.1
        isOptional: true
        parameterType: NUMBER_DOUBLE
      optimizer_step_size:
        defaultValue: 10.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      shuffle_testing_data:
        defaultValue: true
        isOptional: true
        parameterType: BOOLEAN
      shuffle_training_data:
        defaultValue: true
        isOptional: true
        parameterType: BOOLEAN
      testing_batch_size:
        defaultValue: 64.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      training_batch_size:
        defaultValue: 64.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      training_dataset_name:
        defaultValue: ml-25m
        isOptional: true
        parameterType: STRING
      training_epochs:
        defaultValue: 30.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      training_learning_rate:
        defaultValue: 0.001
        isOptional: true
        parameterType: NUMBER_DOUBLE
      validation_batch_size:
        defaultValue: 32.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      validation_threshold:
        defaultValue: 3.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      validation_top_k:
        defaultValue: 50.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.10.1
